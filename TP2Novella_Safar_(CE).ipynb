{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f8739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias que vamos a usar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# aca importamos todas las librerías que vamos a usar\n",
    "\n",
    "# cargamso el dataset, siendo asi elmismoq ue usamos para el tp 1.\n",
    "data = pd.read_csv(\"bank.csv\")\n",
    "\n",
    "# mostrar las primeras filas\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bf323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etapa de preprocesamiento de los datos, para que puedan ser usados posteriormente\n",
    "\n",
    "# columnas con texto, categoricas\n",
    "columnas_categoricas = ['job', 'marital', 'education', 'default', 'housing',\n",
    "                        'loan', 'contact', 'month', 'poutcome']\n",
    "\n",
    "# columnas con números\n",
    "columnas_numericas = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# variables de entrada (X) y salida (y)\n",
    "X = data[columnas_categoricas + columnas_numericas]\n",
    "y = data['deposit'].map({'yes': 1, 'no': 0})  # convertir a 0 y 1\n",
    "\n",
    "# transformamos texto a números y escalamos los valores numéricos\n",
    "transformador = ColumnTransformer([\n",
    "    ('categoricas', OneHotEncoder(handle_unknown='ignore'), columnas_categoricas),\n",
    "    ('numericas', StandardScaler(), columnas_numericas)\n",
    "])\n",
    "\n",
    "X = transformador.fit_transform(X)\n",
    "\n",
    "print(\"datos procesados:\", X.shape)\n",
    "\n",
    "# aca lo que vamos a hacer es preprocesar por asi decirlo los datos, para luego poder usarlos en el modelo de red neuronal. Y gracias a un transformador aplicamos one hot encoding y, vamos a convertir las variables categóricas en numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5788ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos los datos en un conjunto de entrenamiento, validación y test\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=0)\n",
    "\n",
    "print(\"entrenamiento:\", X_train.shape)\n",
    "print(\"validación:\", X_val.shape)\n",
    "print(\"test:\", X_test.shape)\n",
    "\n",
    "# aca dividimos entre train y test, asi vamos a lograr tener un modelo que no overfitee y pueda generalizar bien, cuando se encuentre con datos nuevos, asi logrando un buen desempeño en ambas etapas, no solo en el entrenamiento. Lograndoi que haya digamos un balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Famil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo A - accuracy validación: 0.8387818932533264\n"
     ]
    }
   ],
   "source": [
    "# primer modelo de todos, el modelo A\n",
    "\n",
    "modeloA = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modeloA.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# entrenamos el modelo\n",
    "histA = modeloA.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "# evaluamos el modelo \n",
    "val_lossA, val_accA = modeloA.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"modelo A - accuracy validación:\", val_accA)\n",
    "\n",
    "# aca aparece el priemro modelo de red neuronal. Este en si no es un modelo con mucha cioencia por asi decirlo, pero nos sirve ya que cuenta con dos capas ocultas, asi permitiendonos ver, cuan bien va a funcionar este modelo de red neuronal, basico pero dentro de tdoo bastante eficiente.\n",
    "# vamos a usar relu, y la funcion sigmoidea al final, ya que es un problema de clasificacion binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6caa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo B - accuracy validación: 0.8213165998458862\n"
     ]
    }
   ],
   "source": [
    "# segundo modelo de todos, el modelo B\n",
    "\n",
    "modeloB = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modeloB.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# entrenamos el modelo\n",
    "histB = modeloB.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "# evaluamos el modelo \n",
    "val_lossB, val_accB = modeloB.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"modelo B - accuracy validación:\", val_accB)\n",
    "\n",
    "# aca esta el segundo modelo de red neuronal. Este modelo en si, es mas complejo, ya que cuenta con 3 capaz ocultas, con mas neuronas, que en el anterior modelo. Ambos tienen 20 epoichs, algo que puede modificar mucho el resultado, si no lo ajustamos de manera adecuada.\n",
    "#  de nuevo vamos a usar relu, y la funcion sigmoidea al final, ya que como dijimos antes, es un problema de clasificacion binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235c9aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo C - accuracy validación: 0.8428123593330383\n"
     ]
    }
   ],
   "source": [
    "# tercer modelo de todos, el modelo C\n",
    "\n",
    "modeloC = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modeloC.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# entrenamos el modelo\n",
    "histC = modeloC.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "# evaluamos el modelo\n",
    "val_lossC, val_accC = modeloC.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"modelo C - accuracy validación:\", val_accC)\n",
    "\n",
    "# a primera vista, este modelo puede parecer muy similar al primero, pero al diferencia mas importante, es que la cantidad de neuronas por capa oculta cambia, en este es bastante menor, algo que cambia los resultados. Asi siendo el mejor modelo de todos los que probamos. Tambien este es el que mas rapido entrena, gracias a su menor complejidad digamos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7fc29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mejor modelo elegido con accuracy: 0.8428123593330383\n",
      "accuracy final en test: 0.8392297625541687\n"
     ]
    }
   ],
   "source": [
    "# elegimos el mejor modelo y lo probamos en el test\n",
    "\n",
    "# vemos cuál tuvo mejor accuracy\n",
    "mejor_modelo = None\n",
    "mejor_acc = 0\n",
    "\n",
    "if val_accA > mejor_acc:\n",
    "    mejor_acc = val_accA\n",
    "    mejor_modelo = modeloA\n",
    "if val_accB > mejor_acc:\n",
    "    mejor_acc = val_accB\n",
    "    mejor_modelo = modeloB\n",
    "if val_accC > mejor_acc:\n",
    "    mejor_acc = val_accC\n",
    "    mejor_modelo = modeloC\n",
    "\n",
    "# comparamos la accuracy de los tres modelos, y seleccionamos el mejor de todos. \n",
    "\n",
    "print(\"mejor modelo elegido con accuracy:\", mejor_acc)\n",
    "\n",
    "# entrenamos este modelo con el train mas el validation.\n",
    "mejor_modelo.fit(X_train_full, y_train_full, epochs=20, verbose=0)\n",
    "\n",
    "# evaluamos en el test\n",
    "test_loss, test_acc = mejor_modelo.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"accuracy final en test:\", test_acc)\n",
    "\n",
    "# por ultimo evaluamos el mejor modelo en el test, para ver que tan bien puede generalizar. Vemos que el tercer modeloe s el mejor, y logra una accuracy bastante buena. Poco menor que la accxuracy que tenia en el train, pero aun asi muy buena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en si como conclusion final, creemos que estos resultyados fueron mejores. Ya que  al probar con distintos tipos de modelos de redes neuronales, creemos que el mejor, dentreo de todo fue un modelo poco complejo. Asi logrando ser ejecutado rapidamente.\n",
    "# ademas de que en nuestra opinion a medida de que fuimos haciendo el tp, nos parecio mas interesante usa este tipo de modelos, ya que la estructura para escreiubirlo nos poarece mas amigable digamos, y a pesar de que tuvimos que usar Blackbox AI al principio para entender como funcionaba realmente este modelo (no para escribir el codigo), nos termino pareciendo mejor.\n",
    "# es por eso que consideramos que estos resultados, en accuracy ya de por si fueron mejores, pero creemos que el hecho de que hayamos usado redes neuronales fue mejor, por como es la estructura de el codigo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
